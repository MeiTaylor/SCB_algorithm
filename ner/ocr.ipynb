{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "# 读入图像\n",
    "img = cv2.imread('1.jpg')\n",
    "\n",
    "# 转换为灰度图像\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 使用Otsu's方法进行二值化\n",
    "_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "\n",
    "# 定义一个5x5的结构元素\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5, 5))\n",
    "\n",
    "# 进行开运算\n",
    "opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "from pytesseract import Output\n",
    "\n",
    "# 读入图像\n",
    "img = cv2.imread('1.jpg')\n",
    "\n",
    "# 使用 Tesseract 进行文本检测，返回结果的数据结构为字典\n",
    "d = pytesseract.image_to_data(img, output_type=Output.DICT)\n",
    "\n",
    "# 遍历所有检测到的文本区域\n",
    "n_boxes = len(d['text'])\n",
    "for i in range(n_boxes):\n",
    "    # 如果文本区域的置信度不为0\n",
    "    if int(d['conf'][i]) > 0:\n",
    "        # 获取文本区域的坐标\n",
    "        (x, y, w, h) = (d['left'][i], d['top'][i], d['width'][i], d['height'][i])\n",
    "\n",
    "        # 在原图上画出文本区域\n",
    "        img = cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "# 显示带有文本区域的图像\n",
    "cv2.imshow('img', img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/clovaai/CRAFT-pytorch.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd CRAFT-pytorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python test.py --trained_model=[path_to_your_weight_file] --test_folder=[path_to_your_images]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the image\n",
    "img = cv2.imread('1.jpg')\n",
    "\n",
    "# Convert to grayscale\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Use Otsu's method to binarize the image\n",
    "_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "# Threshold for empty space\n",
    "vertical_empty_space_threshold = binary.shape[1] * 255 * 0.02  # Adjust this value according to your image\n",
    "horizontal_empty_space_threshold = binary.shape[0] * 255 * 0.02  # Adjust this value according to your image\n",
    "\n",
    "# Initialize the previous split point\n",
    "prev_vertical_split_point = 0\n",
    "\n",
    "# Compute the vertical projection of the binary image\n",
    "vertical_projection = np.sum(binary, axis=1)\n",
    "\n",
    "# Find the empty spaces\n",
    "vertical_empty_spaces = np.where(vertical_projection <= vertical_empty_space_threshold)[0]\n",
    "\n",
    "# Initialize the list of split points\n",
    "vertical_split_points = []\n",
    "\n",
    "# Initialize the previous empty space\n",
    "prev_vertical_empty_space = -1\n",
    "\n",
    "# Loop over the empty spaces\n",
    "for empty_space in vertical_empty_spaces:\n",
    "    if prev_vertical_empty_space != -1 and empty_space - prev_vertical_empty_space > 1:\n",
    "        # If there is a gap between two empty spaces, add a split point\n",
    "        vertical_split_points.append((prev_vertical_empty_space + empty_space) // 2)\n",
    "    prev_vertical_empty_space = empty_space\n",
    "\n",
    "# Add the end of the image as the last split point\n",
    "vertical_split_points.append(binary.shape[0])\n",
    "\n",
    "# Loop over the split points\n",
    "for i, vertical_split_point in enumerate(vertical_split_points):\n",
    "    # Cut the image at the split point\n",
    "    vertical_part = img[prev_vertical_split_point:vertical_split_point, :]\n",
    "\n",
    "    # Compute the horizontal projection of the binary image\n",
    "    horizontal_projection = np.sum(binary[prev_vertical_split_point:vertical_split_point, :], axis=0)\n",
    "\n",
    "    # Find the empty spaces\n",
    "    horizontal_empty_spaces = np.where(horizontal_projection <= horizontal_empty_space_threshold)[0]\n",
    "\n",
    "    # Initialize the list of split points\n",
    "    horizontal_split_points = []\n",
    "\n",
    "    # Initialize the previous empty space\n",
    "    prev_horizontal_empty_space = -1\n",
    "\n",
    "    # Loop over the empty spaces\n",
    "    for empty_space in horizontal_empty_spaces:\n",
    "        if prev_horizontal_empty_space != -1 and empty_space - prev_horizontal_empty_space > 1:\n",
    "            # If there is a gap between two empty spaces, add a split point\n",
    "            horizontal_split_points.append((prev_horizontal_empty_space + empty_space) // 2)\n",
    "        prev_horizontal_empty_space = empty_space\n",
    "\n",
    "    # Add the end of the image as the last split point\n",
    "    horizontal_split_points.append(vertical_part.shape[1])\n",
    "\n",
    "    # Initialize the previous split point\n",
    "    prev_horizontal_split_point = 0\n",
    "\n",
    "    # Loop over the split points\n",
    "    for j, horizontal_split_point in enumerate(horizontal_split_points):\n",
    "        # Cut the image at the split point\n",
    "        part = vertical_part[:, prev_horizontal_split_point:horizontal_split_point]\n",
    "\n",
    "        # Save the part\n",
    "        cv2.imwrite(f'picture/part_{i}_{j}.jpg', part)\n",
    "\n",
    "        # Update the previous split point\n",
    "        prev_horizontal_split_point = horizontal_split_point\n",
    "\n",
    "    # Update the previous split point\n",
    "    prev_vertical_split_point = vertical_split_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img = cv2.imread('1.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "_, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "sobelx = cv2.Sobel(binary, cv2.CV_64F, 1, 0, ksize=3)\n",
    "gradient = cv2.convertScaleAbs(sobelx)\n",
    "\n",
    "edge_region_threshold = 50\n",
    "\n",
    "vertical_projection = np.sum(gradient, axis=1)\n",
    "\n",
    "edge_regions = np.where(vertical_projection >= edge_region_threshold)[0]\n",
    "\n",
    "vertical_split_points = []\n",
    "\n",
    "prev_edge_region = -1\n",
    "\n",
    "for edge_region in edge_regions:\n",
    "    if prev_edge_region != -1 and edge_region - prev_edge_region > 1:\n",
    "        vertical_split_points.append((prev_edge_region + edge_region) // 2)\n",
    "    prev_edge_region = edge_region\n",
    "\n",
    "vertical_split_points.append(binary.shape[0])\n",
    "\n",
    "prev_vertical_split_point = 0\n",
    "\n",
    "for i, vertical_split_point in enumerate(vertical_split_points):\n",
    "  \n",
    "    vertical_part = img[prev_vertical_split_point:vertical_split_point, :]\n",
    "\n",
    "    gray_part = cv2.cvtColor(vertical_part, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    _, binary_part = cv2.threshold(gray_part, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    horizontal_projection = np.sum(binary_part, axis=0)\n",
    "\n",
    "    horizontal_empty_spaces = np.where(horizontal_projection <= horizontal_empty_space_threshold)[0]\n",
    "\n",
    "    horizontal_split_points = []\n",
    "\n",
    "    prev_horizontal_empty_space = -1\n",
    "\n",
    "    for empty_space in horizontal_empty_spaces:\n",
    "        if prev_horizontal_empty_space != -1 and empty_space - prev_horizontal_empty_space > 1:\n",
    "            horizontal_split_points.append((prev_horizontal_empty_space + empty_space) // 2)\n",
    "        prev_horizontal_empty_space = empty_space\n",
    "\n",
    "    horizontal_split_points.append(vertical_part.shape[1])\n",
    "\n",
    "    prev_horizontal_split_point = 0\n",
    "\n",
    "    for j, horizontal_split_point in enumerate(horizontal_split_points):\n",
    "        part = vertical_part[:, prev_horizontal_split_point:horizontal_split_point]\n",
    "\n",
    "        cv2.imwrite(f'picture/part_{i}_{j}.jpg', part)\n",
    "\n",
    "        prev_horizontal_split_point = horizontal_split_point\n",
    "\n",
    "    prev_vertical_split_point = vertical_split_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddlehub as hub\n",
    "import cv2\n",
    "\n",
    "# 加载移动端预训练模型\n",
    "ocr = hub.Module(name=\"chinese_ocr_db_crnn_mobile\")\n",
    "\n",
    "# 服务端可以加载大模型，效果更好 -- 【个人电脑，内存不够用】\n",
    "# ocr = hub.Module(name=\"chinese_ocr_db_crnn_server\")\n",
    "\n",
    "# 将预测图片存放在一个文件中(picture.txt)\n",
    "test_img_path = []\n",
    "with open('picture.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        test_img_path.append(line.strip())\n",
    "print(\"预测图片 => \", test_img_path)\n",
    "\n",
    "# 读取测试文件夹test.txt中的照片路径\n",
    "np_images = [cv2.imread(image_path) for image_path in test_img_path]\n",
    "\n",
    "results = ocr.recognize_text(\n",
    "    images=np_images,  # 图片数据，ndarray.shape 为 [H, W, C]，BGR格式；\n",
    "    use_gpu=False,  # 是否使用 GPU；若使用GPU，请先设置CUDA_VISIBLE_DEVICES环境变量\n",
    "    output_dir='ocr_result',  # 图片的保存路径，默认设为 ocr_result；\n",
    "    visualization=True,  # 是否将识别结果保存为图片文件；\n",
    "    box_thresh=0.5,  # 检测文本框置信度的阈值；\n",
    "    text_thresh=0.5)  # 识别中文文本置信度的阈值；\n",
    "\n",
    "for result in results:\n",
    "    data = result['data']\n",
    "    save_path = result['save_path']\n",
    "    for infomation in data:\n",
    "        print('text: ', infomation['text'], '\\nconfidence: ', infomation['confidence'], '\\ntext_box_position: ', infomation['text_box_position'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测图片 =>  ['1.jpg']\n",
      "Download https://bj.bcebos.com/paddlehub/paddlehub_dev/chinese_text_detection_db_mobile_1.1.0.zip\n",
      "[##################################################] 100.00%\n",
      "Decompress C:\\Users\\NIU\\.paddlehub\\tmp\\tmp1vt9bmkz\\chinese_text_detection_db_mobile_1.1.0.zip\n",
      "[##################################################] 100.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[2023-06-10 08:53:12,554] [    INFO]\u001b[0m - Successfully installed dependent packages.\u001b[0mU\\.paddlehub\\tmp\\tmp6ui35gxs\\chinese_text_detection_db_mobile\\requirements.txt: /\u001b[0m\n",
      "\u001b[32m[2023-06-10 08:53:12,799] [    INFO]\u001b[0m - Successfully installed chinese_text_detection_db_mobile-1.1.0\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text:  自我评价 \n",
      "confidence:  0.989576518535614 \n",
      "text_box_position:  [[627, 38], [744, 38], [744, 69], [627, 69]]\n",
      "text:  本人性格开朗、稳重、有活力，待人热情、真诚。有较强的组织 \n",
      "confidence:  0.9970336556434631 \n",
      "text_box_position:  [[575, 85], [1197, 87], [1197, 113], [575, 111]]\n",
      "text:  能力、团体协作精神，较好的社交能力，善于处理各种人际关系。 \n",
      "confidence:  0.9829587936401367 \n",
      "text_box_position:  [[579, 129], [1193, 129], [1193, 153], [579, 153]]\n",
      "text:  能迅速的适应各种环境，并融合其中。能把企业当作家庭，企业 \n",
      "confidence:  0.9984939694404602 \n",
      "text_box_position:  [[577, 171], [1197, 171], [1197, 195], [577, 195]]\n",
      "text:  的财富就是我的财富，在努力为企业服务的过程中实现自身价值 \n",
      "confidence:  0.9995457530021667 \n",
      "text_box_position:  [[575, 213], [1193, 213], [1193, 237], [575, 237]]\n",
      "text:  13899999999 \n",
      "confidence:  0.9987695813179016 \n",
      "text_box_position:  [[968, 308], [1127, 308], [1127, 334], [968, 334]]\n",
      "text:  张吉椎 \n",
      "confidence:  0.8467123508453369 \n",
      "text_box_position:  [[172, 327], [311, 327], [311, 372], [172, 372]]\n",
      "text:  求职意向：行政管理类 \n",
      "confidence:  0.9985655546188354 \n",
      "text_box_position:  [[445, 336], [697, 336], [697, 365], [445, 365]]\n",
      "text:  zhangjiwei@163.com \n",
      "confidence:  0.9824867248535156 \n",
      "text_box_position:  [[974, 365], [1199, 365], [1199, 389], [974, 389]]\n",
      "text:  基本信息 \n",
      "confidence:  0.9990125298500061 \n",
      "text_box_position:  [[145, 458], [267, 458], [267, 495], [145, 495]]\n",
      "text:  工作经历 \n",
      "confidence:  0.998467206954956 \n",
      "text_box_position:  [[625, 451], [747, 451], [747, 487], [625, 487]]\n",
      "text:  出生年月：1998.11 \n",
      "confidence:  0.9965031743049622 \n",
      "text_box_position:  [[106, 526], [294, 526], [294, 551], [106, 551]]\n",
      "text:  2022.3至今 \n",
      "confidence:  0.9928328990936279 \n",
      "text_box_position:  [[627, 535], [745, 535], [745, 559], [627, 559]]\n",
      "text:  部长助理 \n",
      "confidence:  0.9901103973388672 \n",
      "text_box_position:  [[868, 533], [961, 533], [961, 559], [868, 559]]\n",
      "text:  性 \n",
      "confidence:  0.9948091506958008 \n",
      "text_box_position:  [[108, 568], [133, 568], [133, 593], [108, 593]]\n",
      "text:  别：女 \n",
      "confidence:  0.9883285164833069 \n",
      "text_box_position:  [[164, 564], [242, 564], [242, 595], [164, 595]]\n",
      "text:  北京猫眼机械有限公司 \n",
      "confidence:  0.9610474109649658 \n",
      "text_box_position:  [[629, 577], [846, 577], [846, 601], [629, 601]]\n",
      "text:  籍 \n",
      "confidence:  0.9581212997436523 \n",
      "text_box_position:  [[106, 608], [133, 608], [133, 633], [106, 633]]\n",
      "text:  贯：北京海淀区 \n",
      "confidence:  0.9981645345687866 \n",
      "text_box_position:  [[172, 610], [327, 610], [327, 633], [172, 633]]\n",
      "text:  质管部部长助理.负责票证车间生产质量检查，控制，兼 \n",
      "confidence:  0.986253023147583 \n",
      "text_box_position:  [[629, 617], [1148, 617], [1148, 641], [629, 641]]\n",
      "text:  学 \n",
      "confidence:  0.9997939467430115 \n",
      "text_box_position:  [[106, 650], [133, 650], [133, 674], [106, 674]]\n",
      "text:  历：本科 \n",
      "confidence:  0.9903337955474854 \n",
      "text_box_position:  [[168, 652], [259, 652], [259, 676], [168, 676]]\n",
      "text:  任企业内审员，推行IS09001:2008及ISO14000体系并 \n",
      "confidence:  0.9581102728843689 \n",
      "text_box_position:  [[631, 659], [1147, 659], [1147, 683], [631, 683]]\n",
      "text:  政治面貌：党员 \n",
      "confidence:  0.996041476726532 \n",
      "text_box_position:  [[108, 692], [259, 692], [259, 718], [108, 718]]\n",
      "text:  年审。 \n",
      "confidence:  0.9984984397888184 \n",
      "text_box_position:  [[629, 697], [685, 697], [685, 725], [629, 725]]\n",
      "text:  高：178cm \n",
      "confidence:  0.9960673451423645 \n",
      "text_box_position:  [[166, 734], [271, 734], [271, 760], [166, 760]]\n",
      "text:  2021.2-2022.3 \n",
      "confidence:  0.9869008660316467 \n",
      "text_box_position:  [[629, 743], [778, 743], [778, 767], [629, 767]]\n",
      "text:  总经理助理 \n",
      "confidence:  0.9971185922622681 \n",
      "text_box_position:  [[869, 743], [980, 743], [980, 767], [869, 767]]\n",
      "text:  体 \n",
      "confidence:  0.9965471625328064 \n",
      "text_box_position:  [[106, 776], [133, 776], [133, 800], [106, 800]]\n",
      "text:  重：50kg \n",
      "confidence:  0.963866651058197 \n",
      "text_box_position:  [[170, 772], [263, 776], [261, 803], [168, 800]]\n",
      "text:  北京猫眼国际货运代理有限公司 \n",
      "confidence:  0.9783325791358948 \n",
      "text_box_position:  [[625, 781], [937, 780], [937, 809], [625, 811]]\n",
      "text:  根据公司的经营理念和发展战略制定公司各工作岗位 \n",
      "confidence:  0.998105525970459 \n",
      "text_box_position:  [[631, 825], [1147, 825], [1147, 849], [631, 849]]\n",
      "text:  的工作目标：负责制定及推进公司员工的培训、绩效、 \n",
      "confidence:  0.9777393937110901 \n",
      "text_box_position:  [[629, 867], [1137, 867], [1137, 891], [629, 891]]\n",
      "text:  个人技能 \n",
      "confidence:  0.9991288185119629 \n",
      "text_box_position:  [[151, 904], [271, 904], [271, 940], [151, 940]]\n",
      "text:  薪酬的管理。 \n",
      "confidence:  0.9977190494537354 \n",
      "text_box_position:  [[629, 909], [749, 909], [749, 933], [629, 933]]\n",
      "text:  2020.2-2021.2 \n",
      "confidence:  0.9928630590438843 \n",
      "text_box_position:  [[627, 951], [776, 951], [776, 975], [627, 975]]\n",
      "text:  运营助理 \n",
      "confidence:  0.9957942366600037 \n",
      "text_box_position:  [[868, 951], [961, 951], [961, 977], [868, 977]]\n",
      "text:  EXCEL \n",
      "confidence:  0.9969520568847656 \n",
      "text_box_position:  [[110, 964], [170, 964], [170, 990], [110, 990]]\n",
      "text:  北京猫眼文化传媒有限公司 \n",
      "confidence:  0.9704238772392273 \n",
      "text_box_position:  [[627, 990], [893, 990], [893, 1019], [627, 1019]]\n",
      "text:  PPT \n",
      "confidence:  0.978828489780426 \n",
      "text_box_position:  [[112, 1004], [151, 1004], [151, 1034], [112, 1034]]\n",
      "text:  根据目标管理综合考评内容，深入、细致地到所跟踪的 \n",
      "confidence:  0.9976329803466797 \n",
      "text_box_position:  [[629, 1035], [1148, 1035], [1148, 1059], [629, 1059]]\n",
      "text:  WORD \n",
      "confidence:  0.9990993142127991 \n",
      "text_box_position:  [[112, 1046], [162, 1046], [162, 1076], [112, 1076]]\n",
      "text:  各场所了解、掌握情况，帮助和促进各场所提高行政、 \n",
      "confidence:  0.9826686978340149 \n",
      "text_box_position:  [[631, 1076], [1139, 1076], [1139, 1099], [631, 1099]]\n",
      "text:  AI \n",
      "confidence:  0.9888961315155029 \n",
      "text_box_position:  [[114, 1087], [139, 1087], [139, 1118], [114, 1118]]\n",
      "text:  后勤管理水平。 \n",
      "confidence:  0.9924927949905396 \n",
      "text_box_position:  [[629, 1116], [771, 1116], [771, 1141], [629, 1141]]\n",
      "text:  PS \n",
      "confidence:  0.996538519859314 \n",
      "text_box_position:  [[112, 1130], [139, 1130], [139, 1156], [112, 1156]]\n",
      "text:  教育背景 \n",
      "confidence:  0.9994419813156128 \n",
      "text_box_position:  [[623, 1196], [747, 1196], [747, 1233], [623, 1233]]\n",
      "text:  个人爱好 \n",
      "confidence:  0.9994391798973083 \n",
      "text_box_position:  [[149, 1253], [267, 1253], [267, 1289], [149, 1289]]\n",
      "text:  2015-2019 \n",
      "confidence:  0.9986249208450317 \n",
      "text_box_position:  [[627, 1255], [732, 1255], [732, 1280], [627, 1280]]\n",
      "text:  国际经济与贸易 \n",
      "confidence:  0.9993016123771667 \n",
      "text_box_position:  [[869, 1255], [1023, 1255], [1023, 1280], [869, 1280]]\n",
      "text:  北京师范大学 \n",
      "confidence:  0.9997223019599915 \n",
      "text_box_position:  [[629, 1297], [763, 1297], [763, 1322], [629, 1322]]\n",
      "text:  政治经济学、西方经济学、国际经济学、计量经济学、世 \n",
      "confidence:  0.9984428882598877 \n",
      "text_box_position:  [[627, 1337], [1183, 1337], [1183, 1366], [627, 1366]]\n",
      "text:  界经济概论、国际贸易理论与实务、国际金融、国际结算 \n",
      "confidence:  0.9980643391609192 \n",
      "text_box_position:  [[631, 1381], [1178, 1381], [1178, 1405], [631, 1405]]\n",
      "text:  奖励证书 \n",
      "confidence:  0.9996452331542969 \n",
      "text_box_position:  [[625, 1445], [745, 1445], [745, 1476], [625, 1476]]\n",
      "text:  2016 \n",
      "confidence:  0.9995520710945129 \n",
      "text_box_position:  [[625, 1507], [678, 1507], [678, 1532], [625, 1532]]\n",
      "text:  全国大学生英语竞赛一等奖 \n",
      "confidence:  0.9954886436462402 \n",
      "text_box_position:  [[871, 1507], [1133, 1507], [1133, 1531], [871, 1531]]\n",
      "text:  2017 \n",
      "confidence:  0.9997298717498779 \n",
      "text_box_position:  [[627, 1549], [678, 1549], [678, 1574], [627, 1574]]\n",
      "text:  国家级一等奖学金 \n",
      "confidence:  0.9993128776550293 \n",
      "text_box_position:  [[869, 1549], [1046, 1549], [1046, 1574], [869, 1574]]\n",
      "text:  2018 \n",
      "confidence:  0.9993349313735962 \n",
      "text_box_position:  [[625, 1591], [678, 1591], [678, 1616], [625, 1616]]\n",
      "text:  大学英语6级证书（CET-6） \n",
      "confidence:  0.9940415024757385 \n",
      "text_box_position:  [[873, 1591], [1135, 1591], [1135, 1615], [873, 1615]]\n"
     ]
    }
   ],
   "source": [
    "import paddlehub as hub\n",
    "import cv2\n",
    "\n",
    "# 加载移动端预训练模型\n",
    "ocr = hub.Module(name=\"chinese_ocr_db_crnn_mobile\")\n",
    "\n",
    "# 预测图片\n",
    "test_img_path = [\"1.jpg\"]\n",
    "print(\"预测图片 => \", test_img_path)\n",
    "\n",
    "# 读取测试文件夹test.txt中的照片路径\n",
    "np_images = [cv2.imread(image_path) for image_path in test_img_path]\n",
    "\n",
    "results = ocr.recognize_text(\n",
    "    images=np_images,  # 图片数据，ndarray.shape 为 [H, W, C]，BGR格式；\n",
    "    use_gpu=False,  # 是否使用 GPU；若使用GPU，请先设置CUDA_VISIBLE_DEVICES环境变量\n",
    "    output_dir='ocr_result',  # 图片的保存路径，默认设为 ocr_result；\n",
    "    visualization=True,  # 是否将识别结果保存为图片文件；\n",
    "    box_thresh=0.5,  # 检测文本框置信度的阈值；\n",
    "    text_thresh=0.5)  # 识别中文文本置信度的阈值；\n",
    "\n",
    "for result in results:\n",
    "    data = result['data']\n",
    "    save_path = result['save_path']\n",
    "    for infomation in data:\n",
    "        print('text: ', infomation['text'], '\\nconfidence: ', infomation['confidence'], '\\ntext_box_position: ', infomation['text_box_position'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测图片 =>  ['picture\\\\part_0_0.png', 'picture\\\\part_0_1.png', 'picture\\\\part_1_0.png', 'picture\\\\part_2_0.png', 'picture\\\\part_3_0.png', 'picture\\\\part_4_0.png']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import paddlehub as hub\n",
    "\n",
    "# 加载移动端预训练模型\n",
    "ocr = hub.Module(name=\"chinese_ocr_db_crnn_mobile\")\n",
    "\n",
    "# 读取文件夹中的所有图片\n",
    "folder_path = 'picture'\n",
    "test_img_paths = [os.path.join(folder_path, img) for img in os.listdir(folder_path) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "print(\"预测图片 => \", test_img_paths)\n",
    "\n",
    "# 读取测试文件夹中的照片路径\n",
    "np_images = [cv2.imread(image_path) for image_path in test_img_paths]\n",
    "\n",
    "results = ocr.recognize_text(\n",
    "    images=np_images,  \n",
    "    use_gpu=False,  \n",
    "    output_dir='ocr_result',  \n",
    "    visualization=True,  \n",
    "    box_thresh=0.5,  \n",
    "    text_thresh=0.5)\n",
    "\n",
    "# 新建文件用于存储所有识别的文字\n",
    "with open('output.txt', 'w') as f:\n",
    "    for result in results:\n",
    "        data = result['data']\n",
    "        for information in data:\n",
    "            f.write('text: ' + information['text'] + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
